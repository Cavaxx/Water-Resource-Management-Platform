#Dockerfile SPEI calculator
# Use Bitnami Spark 3.3.2 as base image
FROM bitnami/spark:3.3.2

# Switch to root to install packages
USER root

# Install pip and Python dependencies
RUN apt-get update && apt-get install -y python3-pip wget && \
    pip3 install --no-cache-dir numpy pandas scipy

# Add MongoDB Spark Connector JARs (optional but useful for Mongo integration)
RUN wget -P /opt/bitnami/spark/jars/ https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.12/10.3.0/mongo-spark-connector_2.12-10.3.0.jar && \
    wget -P /opt/bitnami/spark/jars/ https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-sync/4.8.2/mongodb-driver-sync-4.8.2.jar && \
    wget -P /opt/bitnami/spark/jars/ https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-core/4.8.2/mongodb-driver-core-4.8.2.jar && \
    wget -P /opt/bitnami/spark/jars/ https://repo1.maven.org/maven2/org/mongodb/bson/4.8.2/bson-4.8.2.jar && \
    wget -P /opt/bitnami/spark/jars/ https://repo1.maven.org/maven2/org/mongodb/bson-record-codec/4.8.2/bson-record-codec-4.8.2.jar

# Copy application code (if shared with master)
COPY ./spark_app /app
WORKDIR /app

# Install application-specific Python dependencies (optional)
COPY requirements.txt /app/requirements.txt
RUN pip3 install --no-cache-dir -r /app/requirements.txt

# Switch back to non-root user
USER 1001

# Optional: Default CMD
CMD ["/opt/bitnami/spark/bin/spark-class", "org.apache.spark.deploy.master.Master"]
